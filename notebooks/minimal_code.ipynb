{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, pickle, itertools, numpy as np, pandas as pd, scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import networkx as nx\n",
    "\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import dgl, dgl.nn.pytorch.conv as conv\n",
    "\n",
    "import phate, umap\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from gode.utils import get_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "\n",
    "# seed for repeatability\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed = 3\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/alzheimer/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_data = np.load(f\"{data_path}/microglia_subtraj_gene_space_for_ritini.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.load(f\"{data_path}/32-granger-preds.npy\")\n",
    "genes = np.load(f\"{data_path}/32-granger-genes.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = np.load(f\"{data_path}/34-adata.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preds[0,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_data = data\n",
    "top_genes = genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# Create a directed graph from the adjacency matrix\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes with labels\n",
    "for i, label in enumerate(top_genes):\n",
    "    G.add_node(i, label=label)\n",
    "\n",
    "# Add edges based on the adjacency matrix\n",
    "for i in range(top_data.shape[0]):\n",
    "    for j in range(top_data.shape[1]):\n",
    "        if top_data[i, j] >= 5.:\n",
    "            G.add_edge(i, j)\n",
    "\n",
    "# Extract node labels\n",
    "labels = nx.get_node_attributes(G, 'label')\n",
    "\n",
    "# Draw the graph\n",
    "pos = nx.spring_layout(G.to_undirected())  # Positioning of nodes\n",
    "plt.figure(figsize=(10,10))\n",
    "nx.draw(G, pos, with_labels=True, labels=labels, node_size=100, node_color='lightblue', edge_color='gray', arrows=True)\n",
    "# nx.draw_networkx_edge_labels(G, pos, edge_labels={(i, j): top_data[i, j] for i, j in G.edges()}, font_color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = list(G.edges())\n",
    "u, v = np.array(edges).T\n",
    "u = torch.IntTensor(u)\n",
    "v = torch.IntTensor(v)\n",
    "\n",
    "\n",
    "g = dgl.graph((u, v))\n",
    "num_edges = g.number_of_edges()\n",
    "\n",
    "# Assign a default edge weight of 1.0 to all edges\n",
    "# g.edata['weight'] = torch.ones(num_edges)\n",
    "\n",
    "g.ndata['feat'] = torch.Tensor(np.ones((len(g.nodes()), 1)))\n",
    "\n",
    "# g = dgl.from_networkx(G)\n",
    "# g.ndata['feat'] = torch.Tensor(np.ones((len(g.nodes()), 1)))\n",
    "\n",
    "\n",
    "ref_g = g.to_networkx()\n",
    "ref_pos = nx.spring_layout(ref_g.to_undirected(), seed=seed)\n",
    "\n",
    "for idx, node in enumerate(ref_g.nodes()):\n",
    "    ref_g.nodes[idx]['color'] = plt.get_cmap('viridis', len(top_genes))(idx)\n",
    "    ref_g.nodes[idx]['label'] = top_genes[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(8, 6))\n",
    "# ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "# nx.draw_networkx_labels(\n",
    "#     ref_g, pos=ref_pos, ax=ax,\n",
    "#     labels=nx.get_node_attributes(ref_g,'label'),\n",
    "#     font_size=12, font_color='black'\n",
    "# )\n",
    "\n",
    "# nx.draw(\n",
    "#     ref_g, pos=ref_pos, ax=ax,\n",
    "#     with_labels=False,\n",
    "#     node_color=list(nx.get_node_attributes(ref_g, 'color').values()),\n",
    "#     edge_cmap=plt.cm.magma,\n",
    "#     node_size=250, arrowsize=25, alpha=0.7\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping for edge ids\n",
    "edge_ids = np.arange(g.number_of_edges())\n",
    "\n",
    "# Shuffle\n",
    "edge_ids = np.random.permutation(edge_ids)\n",
    "\n",
    "test_size_percent = 30\n",
    "test_size_fraction = test_size_percent / 100\n",
    "\n",
    "edge_test_size = int(len(edge_ids) * test_size_fraction)\n",
    "edge_train_size = g.number_of_edges() - edge_test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_test_pos_u = u[edge_ids[:edge_test_size]]\n",
    "edge_test_pos_v = v[edge_ids[:edge_test_size]]\n",
    "\n",
    "edge_train_pos_u = u[edge_ids[edge_test_size:]]\n",
    "edge_train_pos_v = v[edge_ids[edge_test_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjaceny_matrix = nx.adjacency_matrix(G)\n",
    "adjaceny_matrix_negative = 1 - adjaceny_matrix.todense() - np.eye(g.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 4))\n",
    "axes = fig.subplots(1, 2)\n",
    "\n",
    "sns.heatmap(adjaceny_matrix.todense(), label='Adj Mat', ax=axes[0], cbar=False);\n",
    "axes[0].set_title('Adj Mat');\n",
    "sns.heatmap(adjaceny_matrix_negative, label='Neg Adj Mat', ax=axes[1], cbar=False);\n",
    "axes[1].set_title('Neg Adj Mat');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gode.odeblock import ODEBlock\n",
    "from gode.gde import GDEFunc\n",
    "from gode.dgl import DGLSAGEConv, DGLGATConv, MeanAttentionLayer\n",
    "\n",
    "from gode.data import (\n",
    "    make_mean_data_ti, make_train_test_dataframe, \n",
    "    get_data_ti, representative_cell_types_at_t,\n",
    "    sample_group_index, sample_aggregate_group_at_t\n",
    ")\n",
    "\n",
    "def get_data_ti(\n",
    "    df:pd.DataFrame, \n",
    "    t, \n",
    "    size:int,\n",
    "    features,\n",
    "    replace:bool=False,\n",
    "    time_key:str='pseudotime',\n",
    "    groupby:str='cell_types',\n",
    "    device:torch.device=None\n",
    "):\n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "        \n",
    "    return torch.Tensor(\n",
    "        sample_aggregate_group_at_t(\n",
    "            df, t, time_key=time_key, \n",
    "            size=size, replace=replace,\n",
    "            groupby=groupby, features=features\n",
    "        ).values\n",
    "    ).T#.to(device).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_cells_of_type_k_at_time_t(df, n, k, t, genes=top_genes):\n",
    "    n_genes = len(genes)\n",
    "    groups = df.groupby(['cell_types', 'pseudotime'])\n",
    "    if (k, t) not in groups.groups:\n",
    "        values = np.array([[0 for cell in range(n)] for gene in range(n_genes)])\n",
    "    else:\n",
    "        values = groups.get_group((k, t))\\\n",
    "            .filter(genes).sample(n, replace=True)\\\n",
    "            .values.T\n",
    "        \n",
    "    # e.g. shape = (100 genes, 10 cells)\n",
    "    genes_x_cells = values\n",
    "    return genes_x_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_subset_indices = np.where(np.isin(traj_data['genes'], top_genes))[0]\n",
    "np.random.seed(32)\n",
    "cell_subset_indices = np.random.choice(traj_data['trajectories'].shape[1], 50, replace=False)\n",
    "\n",
    "trajs = traj_data['trajectories']\n",
    "trajs = trajs[::3]\n",
    "trajs = trajs[:, cell_subset_indices]\n",
    "trajs = trajs[:, :, gene_subset_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudotimes = np.linspace(0, 1, trajs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_f = trajs.reshape(-1, trajs.shape[2])\n",
    "annot_repeated = np.repeat(traj_data['annotations'][cell_subset_indices], trajs.shape[0])\n",
    "pt_repeated = np.tile(pseudotimes, trajs.shape[1])\n",
    "df = pd.DataFrame(traj_f, columns=top_genes, index=[f'cell_{i}' for i in range(traj_f.shape[0])])\n",
    "df['pseudotime'] = pt_repeated\n",
    "df['cell_types'] = [f'cell_type_{a}' for a in annot_repeated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_cells_of_all_types_at_time_t(df, n, t, types=np.unique(df['cell_types']), genes=top_genes):\n",
    "    return np.hstack(tuple([\n",
    "        get_n_cells_of_type_k_at_time_t(df, n, k, t, genes=genes)\n",
    "        for k in types\n",
    "    ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import pca\n",
    "# import phate\n",
    "# phate_operator = phate.PHATE(t=100)\n",
    "# t_phate = phate_operator.fit_transform(traj_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scprep\n",
    "# scprep.plot.scatter2d(phate_operator.graph.data_nu, df['cell_types'])\n",
    "# scprep.plot.scatter2d(phate_operator.graph.data_nu, df['pseudotime'])\n",
    "# scprep.plot.scatter2d(t_phate, df['cell_types'])\n",
    "# scprep.plot.scatter2d(t_phate, df['pseudotime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = make_train_test_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_u, neg_v = np.where(adjaceny_matrix_negative != 0)\n",
    "neg_edge_ids = np.random.choice(len(neg_u), g.number_of_edges())\n",
    "\n",
    "edge_test_neg_u = neg_u[neg_edge_ids[:edge_test_size]]\n",
    "edge_test_neg_v = neg_v[neg_edge_ids[:edge_test_size]]\n",
    "edge_train_neg_u = neg_u[neg_edge_ids[edge_test_size:]]\n",
    "edge_train_neg_v = neg_v[neg_edge_ids[edge_test_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g = dgl.remove_edges(g, edge_ids[:edge_test_size])\n",
    "\n",
    "train_pos_g = dgl.graph(\n",
    "    (edge_train_pos_u, edge_train_pos_v), \n",
    "    num_nodes=g.number_of_nodes()\n",
    ")\n",
    "\n",
    "train_neg_g = dgl.graph(\n",
    "    (edge_train_neg_u, edge_train_neg_v), \n",
    "    num_nodes=g.number_of_nodes()\n",
    ")\n",
    "\n",
    "test_pos_g = dgl.graph(\n",
    "    (edge_test_pos_u, edge_test_pos_v), \n",
    "    num_nodes=g.number_of_nodes()\n",
    ")\n",
    "\n",
    "test_neg_g = dgl.graph(\n",
    "    (edge_test_neg_u, edge_test_neg_v), \n",
    "    num_nodes=g.number_of_nodes()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGLGATConv(conv.GATConv):\n",
    "    def __init__(self, graph, in_feats, out_feats, num_heads, feat_drop=0.0, attn_drop=0.0, negative_slope=0.2, residual=False, activation=None, allow_zero_in_degree=False, bias=True):\n",
    "        super(DGLGATConv, self).__init__(in_feats, out_feats, num_heads, feat_drop, attn_drop, negative_slope, residual, activation, allow_zero_in_degree, bias)\n",
    "        self.graph = graph\n",
    "\n",
    "    def forward(self, feat, get_attention=False):\n",
    "        return super().forward(self.graph, feat, edge_weight=None, get_attention=get_attention) # updated to address a possible api change in the latest version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cells_at_t = df['pseudotime'].value_counts()[0]\n",
    "\n",
    "time_bins = np.sort(df.pseudotime.unique())\n",
    "cell_types = np.sort(df.cell_types.unique())\n",
    "\n",
    "t0, *_, tn = time_bins\n",
    "time_tensor = torch.Tensor(time_bins)#.to(device)\n",
    "\n",
    "in_feats = cell_types.size * n_cells_at_t\n",
    "out_feats = cell_types.size * n_cells_at_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_names = [top_genes[i] for i in train_g.nodes().numpy()]\n",
    "node_map_full = {n:i for i, n in enumerate(nodes_names)}\n",
    "# tfs = 'gene_0 gene_10 gene_20 gene_30'.split()\n",
    "tfs = top_genes[::5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = nn.Sequential( \n",
    "    DGLGATConv(\n",
    "        train_g,\n",
    "        in_feats=in_feats, out_feats=out_feats, \n",
    "        num_heads=1, residual=False,\n",
    "        activation=nn.Tanh(),\n",
    "        feat_drop=0.0, attn_drop=0.0,\n",
    "        allow_zero_in_degree=True\n",
    "    ),\n",
    "    MeanAttentionLayer(),\n",
    ")\n",
    "\n",
    "gdefunc = GDEFunc(gnn)\n",
    "gde = ODEBlock(func=gdefunc, method='rk4', atol=1e-3, rtol=1e-4, adjoint=False).to(device)\n",
    "model = gde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges_from_graph(g):\n",
    "    u, v = g.edges()\n",
    "    u = u.numpy().tolist()\n",
    "    v = v.numpy().tolist()\n",
    "    edges = np.vstack((u, v)).T\n",
    "    return edges\n",
    "\n",
    "def get_missing_edges_from_edges(g):\n",
    "    nodes = g.nodes().numpy().tolist()\n",
    "    all_edges = list(itertools.product(nodes, nodes))\n",
    "    edges = get_edges_from_graph(g).tolist()  \n",
    "    return list(filter(lambda e: e not in edges, map(list, all_edges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            \n",
    "            # Compute a new edge feature named 'score' by a dot-product between the\n",
    "            # source node feature 'h' and destination node feature 'h'.\n",
    "            \n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            \n",
    "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
    "            return g.edata['score'][:, 0]\n",
    "        \n",
    "        \n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
    "        self.W2 = nn.Linear(h_feats, 1)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        \"\"\"\n",
    "        Computes a scalar score for each edge of the given graph.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        edges :\n",
    "            Has three members ``src``, ``dst`` and ``data``, each of\n",
    "            which is a dictionary representing the features of the\n",
    "            source nodes, the destination nodes, and the edges\n",
    "            themselves.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary of new edge features.\n",
    "        \"\"\"\n",
    "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
    "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = DotPredictor()\n",
    "\n",
    "def compute_link_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.1, weight_decay=5e-4)\n",
    "scheduler = StepLR(optimizer, step_size=350, gamma=0.1)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "steps = 100\n",
    "verbose_step = 1\n",
    "\n",
    "lambda_l1 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gode.plots import custom_features_over_time\n",
    "from gode.data import make_results_dataframe, get_spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_n = 5\n",
    "del_n = 5\n",
    "link_step = 2\n",
    "sample_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t0 = get_n_cells_of_all_types_at_time_t(df_train, n_cells_at_t, 0)\n",
    "# data_t1 = get_n_cells_of_all_types_at_time_t(df_train, n_cells_at_t, _t + 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cell_types = len(df['cell_types'].unique())\n",
    "num_genes = len(top_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "DATA_DIR = './'\n",
    "model = model.to(device)\n",
    "attentions = {}\n",
    "\n",
    "for step_i in range(steps):   \n",
    "    \n",
    "    data_tps = []\n",
    "    data_tis = []\n",
    "    for _t, time_i in enumerate(time_bins[:-1]):    \n",
    "        \n",
    "#         data_t0 = get_data_ti(df_train, _t, sample_size, df_data.columns, replace=True)\n",
    "#         data_t1 = get_data_ti(df_train, _t+1, sample_size, df_data.columns, replace=True)\n",
    "        \n",
    "        data_t0 = get_n_cells_of_all_types_at_time_t(df_train, n_cells_at_t, _t)\n",
    "        data_t1 = get_n_cells_of_all_types_at_time_t(df_train, n_cells_at_t, _t + 1)        \n",
    "        data_t0 = torch.Tensor(data_t0)#.to(device)\n",
    "        data_t1 = torch.Tensor(data_t1)#.to(device)\n",
    "        \n",
    "        t0 = time_bins[_t]\n",
    "        t1 = time_bins[_t + 1]\n",
    "        \n",
    "        model.train()        \n",
    "        data_tp = model(\n",
    "            data_t0,  \n",
    "            torch.Tensor([t0, t1]),#.to(device), \n",
    "            return_whole_sequence=False\n",
    "        )    \n",
    "                \n",
    "        pos_score = pred(train_pos_g, data_tp)\n",
    "        neg_score = pred(train_neg_g, data_tp)\n",
    "        link_loss = compute_link_loss(pos_score, neg_score)\n",
    "        \n",
    "        _, attn = model.func.gnn[0](data_t0, get_attention=True)\n",
    "    \n",
    "        loss = criterion(data_tp, data_t1) + 10 * link_loss # + lambda_l1 * torch.norm(attn, 1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if _t == 0:\n",
    "            data_tis.append(data_t0.clone().detach())\n",
    "        data_tis.append(data_t1.clone().detach())\n",
    "        data_tps.append(data_tp.clone().detach())\n",
    "        \n",
    "    \n",
    "    if step_i % link_step == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # HANDLE LINKS\n",
    "            # Find edges to add\n",
    "            missing_edges = np.array(get_missing_edges_from_edges(train_g)).T\n",
    "            missing_u, missing_v = missing_edges\n",
    "\n",
    "            missing_g = dgl.graph(\n",
    "                (torch.IntTensor(missing_u), torch.IntTensor(missing_v)), \n",
    "                num_nodes=g.number_of_nodes()\n",
    "            )\n",
    "\n",
    "            missing_score = pred(missing_g, data_tp)\n",
    "            missing_idxs = np.argsort(missing_score.numpy())\n",
    "\n",
    "            best_u = missing_u[missing_idxs[-add_n:]]\n",
    "            best_v = missing_v[missing_idxs[-add_n:]]\n",
    "\n",
    "\n",
    "            # Find edges to remove\n",
    "            current_u, current_v = get_edges_from_graph(train_g).T\n",
    "\n",
    "            current_scores = pred(train_g, data_tp)\n",
    "            current_idxs = np.argsort(current_scores.numpy())\n",
    "\n",
    "            worst_u = current_u[current_idxs[:del_n]]\n",
    "            worst_v = current_v[current_idxs[:del_n]]\n",
    "\n",
    "            to_remove = train_g.edge_ids(torch.IntTensor(worst_u), torch.IntTensor(worst_v))\n",
    "    \n",
    "            train_g.remove_edges(to_remove)\n",
    "            train_g.add_edges(torch.IntTensor(best_u), torch.IntTensor(best_v))\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    scheduler.step()   \n",
    "    \n",
    "    if step_i % verbose_step == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "#         data_t0 = get_data_ti(df_train, _t, sample_size, df_data.columns, replace=True)\n",
    "#         data_t1 = get_data_ti(df_train, _t+1, sample_size, df_data.columns, replace=True)\n",
    "        \n",
    "            data_t0 = get_n_cells_of_all_types_at_time_t(df_train, n_cells_at_t, _t)\n",
    "            data_t1 = get_n_cells_of_all_types_at_time_t(df_train, n_cells_at_t, _t + 1)        \n",
    "            data_t0 = torch.Tensor(data_t0)#.to(device)\n",
    "            data_t1 = torch.Tensor(data_t1)#.to(device)\n",
    "        \n",
    "            data_tp = model(data_t0,  time_tensor, return_whole_sequence=True)\n",
    "\n",
    "        \n",
    "            pos_score = pred(test_pos_g, data_tp[-1])\n",
    "            neg_score = pred(test_neg_g, data_tp[-1])\n",
    "            auc_score = compute_auc(pos_score, neg_score)\n",
    "            print('[{}],\\t Loss: {:3.5f},\\t AUC: {:3.5f}'.format(step_i + 1, loss, auc_score)) \n",
    "\n",
    "\n",
    "                \n",
    "        \n",
    "            attns = np.empty(0)\n",
    "            data_tp = data_tps\n",
    "            data_tps = []\n",
    "            data_tis = []\n",
    "            for _t, time_i in enumerate(time_bins[:-1]): \n",
    "#         data_t0 = get_data_ti(df_train, _t, sample_size, df_data.columns, replace=True)\n",
    "#         data_t1 = get_data_ti(df_train, _t+1, sample_size, df_data.columns, replace=True)\n",
    "\n",
    "                data_t0 = get_n_cells_of_all_types_at_time_t(df_train, n_cells_at_t, _t)\n",
    "                data_t1 = get_n_cells_of_all_types_at_time_t(df_train, n_cells_at_t, _t + 1)        \n",
    "                data_t0 = torch.Tensor(data_t0)#.to(device)\n",
    "                data_t1 = torch.Tensor(data_t1)#.to(device)\n",
    "\n",
    "                t0 = time_bins[_t]\n",
    "                t1 = time_bins[_t + 1]\n",
    "\n",
    "                data_tp = model(\n",
    "                    data_t0,  \n",
    "                    torch.Tensor([t0, t1]),#.to(device), \n",
    "                    return_whole_sequence=False\n",
    "                )    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                if _t == 0:\n",
    "                    data_tis.append(data_t0.clone().detach())\n",
    "                data_tis.append(data_t1.clone().detach())\n",
    "                data_tps.append(data_tp.clone().detach())\n",
    "\n",
    "                _, attn = model.func.gnn[0](data_t0, get_attention=True)\n",
    "\n",
    "                attn = attn.reshape(-1).detach().cpu().numpy()        \n",
    "                attns = np.vstack((attns, attn)) if attns.size else attn\n",
    "\n",
    "            attns = np.array(attns)\n",
    "            \n",
    "            if step_i in np.arange(0, steps, 10):#[0, int(steps/2), steps-1]:\n",
    "                data_ti = torch.Tensor(np.array([t.detach().cpu().numpy() for t in data_tis]))\n",
    "                data_tp = torch.Tensor(np.array([t.detach().cpu().numpy() for t in data_tps]))\n",
    "                \n",
    "                dti = data_ti.detach().numpy()\n",
    "                dtp = data_tp.detach().numpy()\n",
    "                \n",
    "                idx = np.arange(num_cell_types) * n_cells_at_t - 1\n",
    "                idx[0] = 0\n",
    "                \n",
    "                dti_t = torch.Tensor(dti[:, :, idx])\n",
    "                dtp_t = torch.Tensor(dtp[:, :, idx])\n",
    "                \n",
    "                # df_res = make_results_dataframe(\n",
    "                #     dti_t, dtp_t, \n",
    "                #     nodes_names, cell_types, tfs\n",
    "                # )\n",
    "                \n",
    "                # df_corr = get_spearmanr(dti_t, dtp_t, columns=cell_types, index=node_map_full)\n",
    "                \n",
    "                # fig = custom_features_over_time(\n",
    "                #     df_res, df_corr,\n",
    "                #     col='tf', row='cell_type',\n",
    "                #     hue='type', x='time', y='expression'\n",
    "                # )            \n",
    "                # fig.savefig(os.path.join(DATA_DIR, f'{n_cells_at_t}_cells_expression_epoch_{step_i}.png'))\n",
    "                \n",
    "                \n",
    "                # nx_g = train_g.to_networkx()\n",
    "\n",
    "                # fig = plt.figure(figsize=(8, 6))\n",
    "                # ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "                # nx.draw_networkx_labels(\n",
    "                #     nx_g, pos=ref_pos, ax=ax,\n",
    "                #     labels=nx.get_node_attributes(ref_g,'label'),\n",
    "                #     font_size=12, font_color='black'\n",
    "                # )\n",
    "\n",
    "                # nx.draw(\n",
    "                #     nx_g, pos=ref_pos, ax=ax,\n",
    "                #     with_labels=False,\n",
    "                #     node_color=list(nx.get_node_attributes(ref_g, 'color').values()),\n",
    "                #     edge_cmap=plt.cm.magma,\n",
    "                #     node_size=500, arrowsize=25, alpha=0.7\n",
    "                # )\n",
    "                \n",
    "                # fig.savefig(os.path.join(DATA_DIR, f'{n_cells_at_t}_cells_graph_epoch_{step_i}.png'))\n",
    "                \n",
    "                attentions[step_i] = np.array(attns)\n",
    "                \n",
    "                \n",
    "            data_tp = np.array([t.detach().cpu().numpy() for t in data_tps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ti = torch.Tensor(np.array([t.detach().cpu().numpy() for t in data_tis]))\n",
    "data_tp = torch.Tensor(np.array([t.detach().cpu().numpy() for t in data_tps]))\n",
    "\n",
    "dti = data_ti.detach().numpy()\n",
    "dtp = data_tp.detach().numpy()\n",
    "\n",
    "idx = np.arange(num_cell_types) * n_cells_at_t - 1\n",
    "idx[0] = 0\n",
    "idx\n",
    "\n",
    "torch.save(data_ti, 'data_ti.pt')\n",
    "torch.save(data_tp, 'data_tp.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to CPU before saving to avoid CUDA issues\n",
    "model_cpu = model.cpu()\n",
    "torch.save(model_cpu.state_dict(), 'model_state_dict.pt')\n",
    "# If you need to save the entire model structure as well, use:\n",
    "torch.save(model_cpu, 'model_full.pt')\n",
    "# Move model back to original device if needed\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti_t = torch.Tensor(dti[:, :, idx])\n",
    "dtp_t = torch.Tensor(dtp[:, :, idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = make_results_dataframe(\n",
    "    dti_t, dtp_t, \n",
    "    nodes_names, cell_types, tfs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = get_spearmanr(dti_t, dtp_t, columns=cell_types, index=node_map_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.to_csv('df_res.csv')\n",
    "df_corr.to_csv('df_corr.csv')\n",
    "# fig = custom_features_over_time("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = custom_features_over_time(\n",
    "#     df_res, df_corr,\n",
    "#     col='tf', row='cell_type',\n",
    "#     hue='type', x='time', y='expression'\n",
    "# )            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_g = train_g.to_networkx()\n",
    "# pos = nx.kamada_kawai_layout(nx_g, scale=1, dim=2)\n",
    "import pickle\n",
    "with open('graph.pkl', 'wb') as f:\n",
    "    pickle.dump(nx_g, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx_g = train_g.to_networkx()\n",
    "\n",
    "# fig = plt.figure(figsize=(8, 6))\n",
    "# ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "# nx.draw_networkx_labels(\n",
    "#     nx_g, pos=ref_pos, ax=ax,\n",
    "#     labels=nx.get_node_attributes(ref_g,'label'),\n",
    "#     font_size=12, font_color='black'\n",
    "# )\n",
    "\n",
    "# nx.draw(\n",
    "#     nx_g, pos=ref_pos, ax=ax,\n",
    "#     with_labels=False,\n",
    "#     node_color=list(nx.get_node_attributes(ref_g, 'color').values()),\n",
    "#     edge_cmap=plt.cm.magma,\n",
    "#     node_size=500, arrowsize=25, alpha=0.7\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_g.remove_edges(train_g.edge_ids(train_g.edges()[0][:100], train_g.edges()[1][:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_g.edges()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx_g = train_g.remove_self_loop().to_networkx()\n",
    "\n",
    "# fig = plt.figure(figsize=(18, 18))\n",
    "# ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "# nx.draw_networkx_labels(\n",
    "#     nx_g, pos=ref_pos, ax=ax,\n",
    "#     labels=nx.get_node_attributes(ref_g,'label'),\n",
    "#     font_size=12, font_color='black'\n",
    "# )\n",
    "\n",
    "# nx.draw(\n",
    "#     nx_g, pos=ref_pos, ax=ax,\n",
    "#     with_labels=False,\n",
    "#     # node_color=list(nx.get_node_attributes(ref_g, 'color').values()),\n",
    "#     node_color='lightblue', edge_color='gray',\n",
    "#     # edge_cmap=plt.cm.magma,\n",
    "#     node_size=500, arrowsize=25, alpha=0.7\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(18, 18))\n",
    "# ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "# nx.draw_networkx_labels(\n",
    "#     ref_g, pos=ref_pos, ax=ax,\n",
    "#     labels=nx.get_node_attributes(ref_g,'label'),\n",
    "#     font_size=12, font_color='black'\n",
    "# )\n",
    "\n",
    "# nx.draw(\n",
    "#     ref_g, pos=ref_pos, ax=ax,\n",
    "#     with_labels=False,\n",
    "#     # node_color=list(nx.get_node_attributes(ref_g, 'color').values()),\n",
    "#     node_color='lightblue', edge_color='gray',\n",
    "#     # edge_cmap=plt.cm.magma,\n",
    "#     node_size=250, arrowsize=25, alpha=0.7\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('graph.pkl', 'wb') as f:\n",
    "#     pickle.dump(nx_g, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj_matrix = nx.to_numpy_array(nx_g)\n",
    "\n",
    "# n_bins = 100  # Number of bins for interpolation\n",
    "\n",
    "# plt.figure(figsize=(20, 18))  \n",
    "# plt.imshow(adj_matrix, cmap='binary')\n",
    "# plt.xticks(ticks=np.arange(len(top_genes)), labels=top_genes, rotation=90)\n",
    "# plt.yticks(ticks=np.arange(len(top_genes)), labels=top_genes)\n",
    "\n",
    "# cbar = plt.colorbar(label='Values', fraction=0.046, pad=0.04, shrink=0.8)\n",
    "# cbar.ax.tick_params(labelsize=20)\n",
    "# cbar.set_label('Values', fontsize=20)\n",
    "# plt.title('GRN inferred from trajectories with Granger Causality', fontsize=20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ritini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
